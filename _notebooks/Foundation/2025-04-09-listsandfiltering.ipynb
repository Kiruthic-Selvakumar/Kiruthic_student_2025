{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "layout: post\n",
    "title: Lists and Filtering\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PopCorn Hack 1: Find Students with Scores in a Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a DataFrame - more complex data structure\n",
    "student_data = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma'],\n",
    "    'Score': [95, 88, 76, 92, 84],\n",
    "    'Grade': ['A', 'B', 'C', 'A', 'B']\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "def find_students_in_range(df, min_score, max_score):\n",
    "    # Filter the DataFrame to find students with scores in the given range\n",
    "    return df[(df['Score'] >= min_score) & (df['Score'] <= max_score)]\n",
    "\n",
    "find_students_in_range(student_data, 80, 90)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PopCorn Hack 2: Calculate Letter Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_letter_grades(df):\n",
    "    def get_letter(score):\n",
    "        if score >= 90:\n",
    "            return 'A'\n",
    "        elif score >= 80:\n",
    "            return 'B'\n",
    "        elif score >= 70:\n",
    "            return 'C'\n",
    "        elif score >= 60:\n",
    "            return 'D'\n",
    "        else:\n",
    "            return 'F'\n",
    "    \n",
    "    df['Letter'] = df['Score'].apply(get_letter)\n",
    "    return df\n",
    "\n",
    "# Sample student data\n",
    "\n",
    "student_data = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma'],\n",
    "    'Score': [95, 88, 76, 92, 84],\n",
    "    'Grade': ['A', 'B', 'C', 'A', 'B']\n",
    "})\n",
    "\n",
    "# Add letter grades\n",
    "add_letter_grades(student_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PopCorn Hack 3: Find the Mode in a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mode(series):\n",
    "    return series.mode().iloc[0]\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "print(find_mode(pd.Series([1, 2, 2, 3, 4, 2, 5])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Assignment: Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## just the prediction model for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class ParkingAvailabilityModel:\n",
    "    def __init__(self):\n",
    "        df = pd.read_csv('data/datasets/treas_parking_payments_2025_datasd.csv')\n",
    "\n",
    "        df['date_trans_start'] = pd.to_datetime(df['date_trans_start'], errors='coerce')\n",
    "        df['day_of_week'] = df['date_trans_start'].dt.dayofweek\n",
    "        df['hour_of_day'] = df['date_trans_start'].dt.hour\n",
    "        df['parking_available'] = 1\n",
    "        df['lagged_parking_available'] = df.groupby('pole_id')['parking_available'].shift(1).fillna(0)\n",
    "        df['time_slot'] = df['day_of_week'].astype(str) + '_' + df['hour_of_day'].astype(str)\n",
    "        df['lagged_day_interaction'] = df['lagged_parking_available'] * df['day_of_week']\n",
    "        df['trans_amt_binned'] = pd.cut(df['trans_amt'], bins=[0, 5, 10, 20, 50, 100, float('inf')], labels=False)\n",
    "        df = df.drop(['date_trans_start', 'date_meter_expire'], axis=1)\n",
    "\n",
    "        pole_id_counts = df['pole_id'].value_counts()\n",
    "        filtered_df = df[~df['pole_id'].isin(pole_id_counts[pole_id_counts == 1].index)]\n",
    "        filtered_df.loc[:, 'parking_available'] = np.where((filtered_df['hour_of_day'] >= 7) & (filtered_df['hour_of_day'] <= 19), 1, 0)\n",
    "\n",
    "        X = filtered_df[['pole_id', 'day_of_week', 'hour_of_day', 'lagged_parking_available',\n",
    "                         'time_slot', 'lagged_day_interaction', 'trans_amt_binned']]\n",
    "        y = filtered_df['parking_available']\n",
    "\n",
    "        X.loc[:, 'pole_id'] = X['pole_id'].astype('category').cat.codes\n",
    "\n",
    "        self.imputer = SimpleImputer(strategy='most_frequent')\n",
    "        X_train_imputed = self.imputer.fit_transform(X)\n",
    "\n",
    "        self.model = LogisticRegression(max_iter=1000, solver='liblinear')\n",
    "        self.model.fit(X_train_imputed, y)\n",
    "\n",
    "    def predict(self, pole_id, day_of_week, hour_of_day):\n",
    "        input_data = pd.DataFrame([[pole_id, day_of_week, hour_of_day, 0, f\"{day_of_week}_{hour_of_day}\", 0, 0]],\n",
    "                                  columns=['pole_id', 'day_of_week', 'hour_of_day',\n",
    "                                           'lagged_parking_available', 'time_slot',\n",
    "                                           'lagged_day_interaction', 'trans_amt_binned'])\n",
    "        input_data.loc[:, 'pole_id'] = input_data['pole_id'].astype('category').cat.codes\n",
    "        input_data_imputed = self.imputer.transform(input_data)\n",
    "        prob = self.model.predict_proba(input_data_imputed)[0][1]\n",
    "        return round(prob * 100, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/datasets/treas_parking_payments_2025_datasd.csv')\n",
    "\n",
    "df['date_trans_start'] = pd.to_datetime(df['date_trans_start'], errors='coerce')\n",
    "df['day_of_week'] = df['date_trans_start'].dt.day_name()\n",
    "df['hour'] = df['date_trans_start'].dt.hour\n",
    "\n",
    "df = df.dropna(subset=['date_trans_start', 'trans_amt'])\n",
    "\n",
    "# Show the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Find parking transactions with highest and lowest transaction amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pandas \n",
    "highest = df[df['trans_amt'] == max_amt]\n",
    "lowest = df[df['trans_amt'] == min_amt]\n",
    "\n",
    "highest[['pole_id', 'trans_amt', 'date_trans_start']]\n",
    "lowest[['pole_id', 'trans_amt', 'date_trans_start']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the difference between max and min transaction amount per pole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pole_diff = df.groupby('pole_id')['trans_amt'].agg(['max', 'min'])\n",
    "pole_diff['difference'] = pole_diff['max'] - pole_diff['min']\n",
    "pole_diff.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify all poles where a transaction exceeded the average amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trans_amt = df['trans_amt'].mean()\n",
    "above_avg = df[df['trans_amt'] > avg_trans_amt]\n",
    "\n",
    "print(f\"Average transaction amount: ${avg_trans_amt:.2f}\")\n",
    "above_avg[['pole_id', 'trans_amt', 'date_trans_start']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by day of week and hour, and calculate average transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['day_of_week', 'hour'])[['trans_amt']].mean().reset_index()\n",
    "grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS + questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transactions vs day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_avg = df.groupby('day_of_week')['trans_amt'].mean().sort_values()\n",
    "day_avg.plot(kind='bar', title=\"Average Transaction by Day\", figsize=(8, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows which days have higher transaction amounts, and also indicates more parking demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which hour of the day has the highest average transaction amount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_avg = df.groupby('hour')['trans_amt'].mean().sort_values(ascending=False)\n",
    "top_hour = hour_avg.idxmax()\n",
    "top_value = hour_avg.max()\n",
    "print(f\"Highest average transaction is at {top_hour}:00 with ${top_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What percentage of transactions were over $5.00?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_5 = df[df['trans_amt'] > 5]\n",
    "percent_over_5 = (len(over_5) / len(df)) * 100\n",
    "print(f\"{percent_over_5:.2f}% of transactions were over $5.00\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite Db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __init__ import db, app\n",
    "from model.parking import ParkingSpot\n",
    "from model.user import User\n",
    "\n",
    "class ParkingData(db.Model):\n",
    "    __tablename__ = 'parking_data'\n",
    "\n",
    "    id = db.Column(db.Integer, primary_key=True)\n",
    "    _amount_paid = db.Column(db.Float, nullable=False)\n",
    "    _user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)\n",
    "    _parking_spot_id = db.Column(db.Integer, db.ForeignKey('parking_spots.id'), nullable=False)\n",
    "    _transaction_time = db.Column(db.DateTime, nullable=False)\n",
    "\n",
    "    def __init__(self, amount_paid, user_id, parking_spot_id, transaction_time):\n",
    "        self._amount_paid = amount_paid\n",
    "        self._user_id = user_id\n",
    "        self._parking_spot_id = parking_spot_id\n",
    "        self._transaction_time = transaction_time\n",
    "\n",
    "    def create(self):\n",
    "        try:\n",
    "            db.session.add(self)\n",
    "            db.session.commit()\n",
    "        except Exception as e:\n",
    "            db.session.rollback()\n",
    "            raise e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = db.session.query(\n",
    "    ParkingData._parking_spot_id,\n",
    "    db.func.avg(ParkingData._amount_paid).label('avg_amount_paid')\n",
    ").group_by(ParkingData._parking_spot_id)\n",
    "\n",
    "df_avg_per_spot = pd.read_sql(query.statement, db.session.bind)\n",
    "print(df_avg_per_spot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = db.session.query(\n",
    "    ParkingData._parking_spot_id,\n",
    "    db.func.max(ParkingData._amount_paid).label('max_amount_paid'),\n",
    "    db.func.min(ParkingData._amount_paid).label('min_amount_paid')\n",
    ").group_by(ParkingData._parking_spot_id)\n",
    "\n",
    "df_high_low = pd.read_sql(query.statement, db.session.bind)\n",
    "print(df_high_low)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = db.session.query(\n",
    "    ParkingData._user_id,\n",
    "    db.func.count().label('transaction_count')\n",
    ").group_by(ParkingData._user_id)\n",
    "\n",
    "df_user_transactions = pd.read_sql(query.statement, db.session.bind)\n",
    "print(df_user_transactions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis/ Comparison\n",
    "\n",
    "Pandas is helpful when you want to quickly look at and work with data in Python, especially if the file is small and on your computer. SQL is better when the data is large or stored in a database, because it can filter and sort before loading. Pandas is easier for testing ideas, but SQL is more efficient for handling big or shared data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
